{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58c4066a-9b58-45e3-ba0a-f96a2402ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re(regular expression)=useful for tasks like cleaning text data,manipulation\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92cbbf1a-38da-432a-baa1-3a308c1e5f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'intelligence', 'ai', 'has', 'rapidly', 'evolved', 'from', 'a', 'futuristic', 'concept', 'to', 'an', 'integral', 'part', 'of', 'our', 'everyday', 'lives', 'revolutionizing', 'industries', 'enhancing', 'personal', 'convenience', 'and', 'reshaping', 'global', 'dynamics', 'in', 'recent', 'years', 'advancements', 'in', 'machine', 'learning', 'deep', 'learning', 'and', 'neural', 'networks', 'have', 'propelled', 'ai', 'to', 'new', 'heights', 'enabling', 'it', 'to', 'process', 'vast', 'amounts', 'of', 'data', 'recognize', 'complex', 'patterns', 'and', 'make', 'predictions', 'with', 'remarkable', 'accuracy', 'in', 'sectors', 'like', 'healthcare', 'ai', 'assists', 'in', 'diagnosing', 'diseases', 'and', 'personalizing', 'treatment', 'plans', 'potentially', 'saving', 'lives', 'through', 'early', 'detection', 'and', 'precision', 'medicine', 'in', 'finance', 'algorithms', 'analyze', 'market', 'trends', 'and', 'make', 'investment', 'decisions', 'faster', 'than', 'any', 'human', 'could', 'optimizing', 'returns', 'and', 'mitigating', 'risks', 'ai', 's', 'impact', 'extends', 'to', 'everyday', 'applications', 'such', 'as', 'smart', 'homes', 'where', 'voice', 'activated', 'assistants', 'like', 'alexa', 'and', 'google', 'home', 'are', 'transforming', 'how', 'we', 'interact', 'with', 'technology', 'the', 'educational', 'sector', 'is', 'seeing', 'a', 'transformation', 'as', 'well', 'with', 'ai', 'powered', 'platforms', 'providing', 'personalized', 'learning', 'experiences', 'and', 'assisting', 'teachers', 'in', 'managing', 'and', 'analyzing', 'student', 'performance', 'data', 'however', 'the', 'rise', 'of', 'ai', 'also', 'brings', 'challenges', 'and', 'ethical', 'questions', 'issues', 'surrounding', 'data', 'privacy', 'job', 'displacement', 'due', 'to', 'automation', 'and', 'the', 'risk', 'of', 'biases', 'in', 'ai', 'models', 'highlight', 'the', 'need', 'for', 'responsible', 'development', 'and', 'regulation', 'as', 'we', 'continue', 'to', 'innovate', 'it', 'is', 'essential', 'to', 'ensure', 'that', 'ai', 'serves', 'humanity', 's', 'best', 'interests', 'promoting', 'fairness', 'accountability', 'and', 'transparency', 'embracing', 'ai', 's', 'potential', 'while', 'addressing', 'these', 'concerns', 'could', 'lead', 'to', 'a', 'future', 'where', 'technology', 'empowers', 'individuals', 'and', 'communities', 'driving', 'us', 'towards', 'unprecedented', 'levels', 'of', 'efficiency', 'creativity', 'and', 'prosperity']\n"
     ]
    }
   ],
   "source": [
    "with open(\"CBOW.txt\",\"r\") as f:\n",
    "    doc1=f.read().lower()\n",
    "l_doc1=re.sub(r\"[^a-zA-Z0-9]\",\" \",doc1).split()\n",
    "print(l_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8c40549-d6ad-4c25-a2e3-346166643b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artificial': 1, 'intelligence': 1, 'ai': 9, 'has': 1, 'rapidly': 1, 'evolved': 1, 'from': 1, 'a': 3, 'futuristic': 1, 'concept': 1, 'to': 8, 'an': 1, 'integral': 1, 'part': 1, 'of': 5, 'our': 1, 'everyday': 2, 'lives': 2, 'revolutionizing': 1, 'industries': 1, 'enhancing': 1, 'personal': 1, 'convenience': 1, 'and': 16, 'reshaping': 1, 'global': 1, 'dynamics': 1, 'in': 7, 'recent': 1, 'years': 1, 'advancements': 1, 'machine': 1, 'learning': 3, 'deep': 1, 'neural': 1, 'networks': 1, 'have': 1, 'propelled': 1, 'new': 1, 'heights': 1, 'enabling': 1, 'it': 2, 'process': 1, 'vast': 1, 'amounts': 1, 'data': 3, 'recognize': 1, 'complex': 1, 'patterns': 1, 'make': 2, 'predictions': 1, 'with': 3, 'remarkable': 1, 'accuracy': 1, 'sectors': 1, 'like': 2, 'healthcare': 1, 'assists': 1, 'diagnosing': 1, 'diseases': 1, 'personalizing': 1, 'treatment': 1, 'plans': 1, 'potentially': 1, 'saving': 1, 'through': 1, 'early': 1, 'detection': 1, 'precision': 1, 'medicine': 1, 'finance': 1, 'algorithms': 1, 'analyze': 1, 'market': 1, 'trends': 1, 'investment': 1, 'decisions': 1, 'faster': 1, 'than': 1, 'any': 1, 'human': 1, 'could': 2, 'optimizing': 1, 'returns': 1, 'mitigating': 1, 'risks': 1, 's': 3, 'impact': 1, 'extends': 1, 'applications': 1, 'such': 1, 'as': 3, 'smart': 1, 'homes': 1, 'where': 2, 'voice': 1, 'activated': 1, 'assistants': 1, 'alexa': 1, 'google': 1, 'home': 1, 'are': 1, 'transforming': 1, 'how': 1, 'we': 2, 'interact': 1, 'technology': 2, 'the': 4, 'educational': 1, 'sector': 1, 'is': 2, 'seeing': 1, 'transformation': 1, 'well': 1, 'powered': 1, 'platforms': 1, 'providing': 1, 'personalized': 1, 'experiences': 1, 'assisting': 1, 'teachers': 1, 'managing': 1, 'analyzing': 1, 'student': 1, 'performance': 1, 'however': 1, 'rise': 1, 'also': 1, 'brings': 1, 'challenges': 1, 'ethical': 1, 'questions': 1, 'issues': 1, 'surrounding': 1, 'privacy': 1, 'job': 1, 'displacement': 1, 'due': 1, 'automation': 1, 'risk': 1, 'biases': 1, 'models': 1, 'highlight': 1, 'need': 1, 'for': 1, 'responsible': 1, 'development': 1, 'regulation': 1, 'continue': 1, 'innovate': 1, 'essential': 1, 'ensure': 1, 'that': 1, 'serves': 1, 'humanity': 1, 'best': 1, 'interests': 1, 'promoting': 1, 'fairness': 1, 'accountability': 1, 'transparency': 1, 'embracing': 1, 'potential': 1, 'while': 1, 'addressing': 1, 'these': 1, 'concerns': 1, 'lead': 1, 'future': 1, 'empowers': 1, 'individuals': 1, 'communities': 1, 'driving': 1, 'us': 1, 'towards': 1, 'unprecedented': 1, 'levels': 1, 'efficiency': 1, 'creativity': 1, 'prosperity': 1}\n"
     ]
    }
   ],
   "source": [
    "#calculation of BOW\n",
    "def calculationBOW(words):\n",
    "    bow={}\n",
    "    for word in words:\n",
    "        if word in bow:\n",
    "            bow[word]+=1\n",
    "        else:\n",
    "            bow[word]=1\n",
    "    return bow\n",
    "bow=calculationBOW(l_doc1)\n",
    "print(bow)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd652a2b-2fd2-44d7-ae0e-6106a2c3dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1  1  1  8  1  1  1  1  1  1  1  1 16  1  1  1  1  3  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  2  1  3  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  7  1  1  1  1  1  1  1  1  2  1  2  1  1\n",
      "   3  1  2  2  1  2  1  1  1  1  1  1  1  1  1  5  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  1  1  1  1  2  1  1  4  1  1  8  1  1  1  1  1\n",
      "   1  1  1  1  1  2  1  2  1  3  1]]\n"
     ]
    }
   ],
   "source": [
    "vetorizer=CountVectorizer()\n",
    "x=vectorizer.fit_transform([doc1])\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50a609c8-fa06-480a-8951-a5bb1c932300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 0, 'of': 1, 'managing': 2, 'potentially': 3, 'risk': 4, 'such': 5, 'diagnosing': 6, 'educational': 7, 'best': 8, 'medicine': 9, 'individuals': 10, 'where': 11, 'artificial': 12, 'technology': 13, 'challenges': 14, 'accuracy': 15, 'personal': 16, 'early': 17, 'analyze': 18, 'could': 19, 'interact': 20, 'essential': 21, 'homes': 22, 'through': 23, 'applications': 24, 'analyzing': 25, 'evolved': 26, 'sector': 27, 'diseases': 28, 'automation': 29, 'and': 30, 'industries': 31, 'data': 32, 'efficiency': 33, 'our': 34, 'enhancing': 35, 'questions': 36, 'embracing': 37, 'advancements': 38, 'smart': 39, 'treatment': 40, 'amounts': 41, 'it': 42, 'surrounding': 43, 'futuristic': 44, 'an': 45, 'is': 46, 'ethical': 47, 'voice': 48, 'responsible': 49, 'to': 50, 'healthcare': 51, 'potential': 52, 'activated': 53, 'how': 54, 'saving': 55, 'promoting': 56, 'intelligence': 57, 'from': 58, 'we': 59, 'future': 60, 'new': 61, 'towards': 62, 'enabling': 63, 'alexa': 64, 'privacy': 65, 'due': 66, 'ensure': 67, 'risks': 68, 'highlight': 69, 'student': 70, 'as': 71, 'with': 72, 'also': 73, 'providing': 74, 'assisting': 75, 'assistants': 76, 'revolutionizing': 77, 'vast': 78, 'teachers': 79, 'performance': 80, 'rise': 81, 'complex': 82, 'job': 83, 'serves': 84, 'concerns': 85, 'us': 86, 'process': 87, 'impact': 88, 'while': 89, 'mitigating': 90, 'everyday': 91, 'networks': 92, 'any': 93, 'neural': 94, 'transforming': 95, 'heights': 96, 'are': 97, 'these': 98, 'in': 99, 'predictions': 100, 'decisions': 101, 'unprecedented': 102, 'models': 103, 'than': 104, 'global': 105, 'seeing': 106, 'transparency': 107, 'deep': 108, 'optimizing': 109, 'returns': 110, 'market': 111, 'empowers': 112, 'innovate': 113, 'a': 114, 'regulation': 115, 'prosperity': 116, 'has': 117, 'human': 118, 'lives': 119, 'biases': 120, 'displacement': 121, 'recent': 122, 'propelled': 123, 'faster': 124, 'platforms': 125, 'precision': 126, 'lead': 127, 'creativity': 128, 'years': 129, 'that': 130, 'integral': 131, 'personalizing': 132, 'convenience': 133, 'patterns': 134, 'driving': 135, 'reshaping': 136, 'have': 137, 'humanity': 138, 'part': 139, 'issues': 140, 'personalized': 141, 'brings': 142, 's': 143, 'detection': 144, 'communities': 145, 'transformation': 146, 'concept': 147, 'remarkable': 148, 'like': 149, 'the': 150, 'sectors': 151, 'accountability': 152, 'however': 153, 'interests': 154, 'addressing': 155, 'rapidly': 156, 'extends': 157, 'continue': 158, 'machine': 159, 'levels': 160, 'assists': 161, 'learning': 162, 'make': 163, 'for': 164, 'finance': 165, 'fairness': 166, 'well': 167, 'development': 168, 'plans': 169, 'home': 170, 'trends': 171, 'algorithms': 172, 'powered': 173, 'experiences': 174, 'recognize': 175, 'dynamics': 176, 'need': 177, 'google': 178, 'investment': 179}\n"
     ]
    }
   ],
   "source": [
    "#Embeddings=capture their meanings and relationships.They transform text into vectors so that words with similar meanings are closer together.\n",
    "\n",
    "vocab_size=len(set(l_doc1))  #determine no of unique words and convert it into set\n",
    "embed_dim=10  #size of each word vector\n",
    "\n",
    "#create a dictionry where each unique word map to each index\n",
    "word_to_ix={word : i for i,word in enumerate(set(l_doc1))}\n",
    "print(word_to_ix) \n",
    "\n",
    "embeddings=np.random.random_sample((vocab_size,embed_dim))\n",
    "# creates a context window of two words before and two words after the target word.\n",
    "data=[([l_doc1[i-2],l_doc1[i-1],l_doc1[i+1],l_doc1[i+2]],l_doc1[i])\n",
    "     for i in range(2,len(l_doc1)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c583c535-5988-4cd4-92bf-1e7c923389f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['artificial', 'intelligence', 'has', 'rapidly'], 'ai'), (['intelligence', 'ai', 'rapidly', 'evolved'], 'has'), (['ai', 'has', 'evolved', 'from'], 'rapidly'), (['has', 'rapidly', 'from', 'a'], 'evolved'), (['rapidly', 'evolved', 'a', 'futuristic'], 'from'), (['evolved', 'from', 'futuristic', 'concept'], 'a'), (['from', 'a', 'concept', 'to'], 'futuristic'), (['a', 'futuristic', 'to', 'an'], 'concept'), (['futuristic', 'concept', 'an', 'integral'], 'to'), (['concept', 'to', 'integral', 'part'], 'an'), (['to', 'an', 'part', 'of'], 'integral'), (['an', 'integral', 'of', 'our'], 'part'), (['integral', 'part', 'our', 'everyday'], 'of'), (['part', 'of', 'everyday', 'lives'], 'our'), (['of', 'our', 'lives', 'revolutionizing'], 'everyday'), (['our', 'everyday', 'revolutionizing', 'industries'], 'lives'), (['everyday', 'lives', 'industries', 'enhancing'], 'revolutionizing'), (['lives', 'revolutionizing', 'enhancing', 'personal'], 'industries'), (['revolutionizing', 'industries', 'personal', 'convenience'], 'enhancing'), (['industries', 'enhancing', 'convenience', 'and'], 'personal'), (['enhancing', 'personal', 'and', 'reshaping'], 'convenience'), (['personal', 'convenience', 'reshaping', 'global'], 'and'), (['convenience', 'and', 'global', 'dynamics'], 'reshaping'), (['and', 'reshaping', 'dynamics', 'in'], 'global'), (['reshaping', 'global', 'in', 'recent'], 'dynamics'), (['global', 'dynamics', 'recent', 'years'], 'in'), (['dynamics', 'in', 'years', 'advancements'], 'recent'), (['in', 'recent', 'advancements', 'in'], 'years'), (['recent', 'years', 'in', 'machine'], 'advancements'), (['years', 'advancements', 'machine', 'learning'], 'in'), (['advancements', 'in', 'learning', 'deep'], 'machine'), (['in', 'machine', 'deep', 'learning'], 'learning'), (['machine', 'learning', 'learning', 'and'], 'deep'), (['learning', 'deep', 'and', 'neural'], 'learning'), (['deep', 'learning', 'neural', 'networks'], 'and'), (['learning', 'and', 'networks', 'have'], 'neural'), (['and', 'neural', 'have', 'propelled'], 'networks'), (['neural', 'networks', 'propelled', 'ai'], 'have'), (['networks', 'have', 'ai', 'to'], 'propelled'), (['have', 'propelled', 'to', 'new'], 'ai'), (['propelled', 'ai', 'new', 'heights'], 'to'), (['ai', 'to', 'heights', 'enabling'], 'new'), (['to', 'new', 'enabling', 'it'], 'heights'), (['new', 'heights', 'it', 'to'], 'enabling'), (['heights', 'enabling', 'to', 'process'], 'it'), (['enabling', 'it', 'process', 'vast'], 'to'), (['it', 'to', 'vast', 'amounts'], 'process'), (['to', 'process', 'amounts', 'of'], 'vast'), (['process', 'vast', 'of', 'data'], 'amounts'), (['vast', 'amounts', 'data', 'recognize'], 'of'), (['amounts', 'of', 'recognize', 'complex'], 'data'), (['of', 'data', 'complex', 'patterns'], 'recognize'), (['data', 'recognize', 'patterns', 'and'], 'complex'), (['recognize', 'complex', 'and', 'make'], 'patterns'), (['complex', 'patterns', 'make', 'predictions'], 'and'), (['patterns', 'and', 'predictions', 'with'], 'make'), (['and', 'make', 'with', 'remarkable'], 'predictions'), (['make', 'predictions', 'remarkable', 'accuracy'], 'with'), (['predictions', 'with', 'accuracy', 'in'], 'remarkable'), (['with', 'remarkable', 'in', 'sectors'], 'accuracy'), (['remarkable', 'accuracy', 'sectors', 'like'], 'in'), (['accuracy', 'in', 'like', 'healthcare'], 'sectors'), (['in', 'sectors', 'healthcare', 'ai'], 'like'), (['sectors', 'like', 'ai', 'assists'], 'healthcare'), (['like', 'healthcare', 'assists', 'in'], 'ai'), (['healthcare', 'ai', 'in', 'diagnosing'], 'assists'), (['ai', 'assists', 'diagnosing', 'diseases'], 'in'), (['assists', 'in', 'diseases', 'and'], 'diagnosing'), (['in', 'diagnosing', 'and', 'personalizing'], 'diseases'), (['diagnosing', 'diseases', 'personalizing', 'treatment'], 'and'), (['diseases', 'and', 'treatment', 'plans'], 'personalizing'), (['and', 'personalizing', 'plans', 'potentially'], 'treatment'), (['personalizing', 'treatment', 'potentially', 'saving'], 'plans'), (['treatment', 'plans', 'saving', 'lives'], 'potentially'), (['plans', 'potentially', 'lives', 'through'], 'saving'), (['potentially', 'saving', 'through', 'early'], 'lives'), (['saving', 'lives', 'early', 'detection'], 'through'), (['lives', 'through', 'detection', 'and'], 'early'), (['through', 'early', 'and', 'precision'], 'detection'), (['early', 'detection', 'precision', 'medicine'], 'and'), (['detection', 'and', 'medicine', 'in'], 'precision'), (['and', 'precision', 'in', 'finance'], 'medicine'), (['precision', 'medicine', 'finance', 'algorithms'], 'in'), (['medicine', 'in', 'algorithms', 'analyze'], 'finance'), (['in', 'finance', 'analyze', 'market'], 'algorithms'), (['finance', 'algorithms', 'market', 'trends'], 'analyze'), (['algorithms', 'analyze', 'trends', 'and'], 'market'), (['analyze', 'market', 'and', 'make'], 'trends'), (['market', 'trends', 'make', 'investment'], 'and'), (['trends', 'and', 'investment', 'decisions'], 'make'), (['and', 'make', 'decisions', 'faster'], 'investment'), (['make', 'investment', 'faster', 'than'], 'decisions'), (['investment', 'decisions', 'than', 'any'], 'faster'), (['decisions', 'faster', 'any', 'human'], 'than'), (['faster', 'than', 'human', 'could'], 'any'), (['than', 'any', 'could', 'optimizing'], 'human'), (['any', 'human', 'optimizing', 'returns'], 'could'), (['human', 'could', 'returns', 'and'], 'optimizing'), (['could', 'optimizing', 'and', 'mitigating'], 'returns'), (['optimizing', 'returns', 'mitigating', 'risks'], 'and'), (['returns', 'and', 'risks', 'ai'], 'mitigating'), (['and', 'mitigating', 'ai', 's'], 'risks'), (['mitigating', 'risks', 's', 'impact'], 'ai'), (['risks', 'ai', 'impact', 'extends'], 's'), (['ai', 's', 'extends', 'to'], 'impact'), (['s', 'impact', 'to', 'everyday'], 'extends'), (['impact', 'extends', 'everyday', 'applications'], 'to'), (['extends', 'to', 'applications', 'such'], 'everyday'), (['to', 'everyday', 'such', 'as'], 'applications'), (['everyday', 'applications', 'as', 'smart'], 'such'), (['applications', 'such', 'smart', 'homes'], 'as'), (['such', 'as', 'homes', 'where'], 'smart'), (['as', 'smart', 'where', 'voice'], 'homes'), (['smart', 'homes', 'voice', 'activated'], 'where'), (['homes', 'where', 'activated', 'assistants'], 'voice'), (['where', 'voice', 'assistants', 'like'], 'activated'), (['voice', 'activated', 'like', 'alexa'], 'assistants'), (['activated', 'assistants', 'alexa', 'and'], 'like'), (['assistants', 'like', 'and', 'google'], 'alexa'), (['like', 'alexa', 'google', 'home'], 'and'), (['alexa', 'and', 'home', 'are'], 'google'), (['and', 'google', 'are', 'transforming'], 'home'), (['google', 'home', 'transforming', 'how'], 'are'), (['home', 'are', 'how', 'we'], 'transforming'), (['are', 'transforming', 'we', 'interact'], 'how'), (['transforming', 'how', 'interact', 'with'], 'we'), (['how', 'we', 'with', 'technology'], 'interact'), (['we', 'interact', 'technology', 'the'], 'with'), (['interact', 'with', 'the', 'educational'], 'technology'), (['with', 'technology', 'educational', 'sector'], 'the'), (['technology', 'the', 'sector', 'is'], 'educational'), (['the', 'educational', 'is', 'seeing'], 'sector'), (['educational', 'sector', 'seeing', 'a'], 'is'), (['sector', 'is', 'a', 'transformation'], 'seeing'), (['is', 'seeing', 'transformation', 'as'], 'a'), (['seeing', 'a', 'as', 'well'], 'transformation'), (['a', 'transformation', 'well', 'with'], 'as'), (['transformation', 'as', 'with', 'ai'], 'well'), (['as', 'well', 'ai', 'powered'], 'with'), (['well', 'with', 'powered', 'platforms'], 'ai'), (['with', 'ai', 'platforms', 'providing'], 'powered'), (['ai', 'powered', 'providing', 'personalized'], 'platforms'), (['powered', 'platforms', 'personalized', 'learning'], 'providing'), (['platforms', 'providing', 'learning', 'experiences'], 'personalized'), (['providing', 'personalized', 'experiences', 'and'], 'learning'), (['personalized', 'learning', 'and', 'assisting'], 'experiences'), (['learning', 'experiences', 'assisting', 'teachers'], 'and'), (['experiences', 'and', 'teachers', 'in'], 'assisting'), (['and', 'assisting', 'in', 'managing'], 'teachers'), (['assisting', 'teachers', 'managing', 'and'], 'in'), (['teachers', 'in', 'and', 'analyzing'], 'managing'), (['in', 'managing', 'analyzing', 'student'], 'and'), (['managing', 'and', 'student', 'performance'], 'analyzing'), (['and', 'analyzing', 'performance', 'data'], 'student'), (['analyzing', 'student', 'data', 'however'], 'performance'), (['student', 'performance', 'however', 'the'], 'data'), (['performance', 'data', 'the', 'rise'], 'however'), (['data', 'however', 'rise', 'of'], 'the'), (['however', 'the', 'of', 'ai'], 'rise'), (['the', 'rise', 'ai', 'also'], 'of'), (['rise', 'of', 'also', 'brings'], 'ai'), (['of', 'ai', 'brings', 'challenges'], 'also'), (['ai', 'also', 'challenges', 'and'], 'brings'), (['also', 'brings', 'and', 'ethical'], 'challenges'), (['brings', 'challenges', 'ethical', 'questions'], 'and'), (['challenges', 'and', 'questions', 'issues'], 'ethical'), (['and', 'ethical', 'issues', 'surrounding'], 'questions'), (['ethical', 'questions', 'surrounding', 'data'], 'issues'), (['questions', 'issues', 'data', 'privacy'], 'surrounding'), (['issues', 'surrounding', 'privacy', 'job'], 'data'), (['surrounding', 'data', 'job', 'displacement'], 'privacy'), (['data', 'privacy', 'displacement', 'due'], 'job'), (['privacy', 'job', 'due', 'to'], 'displacement'), (['job', 'displacement', 'to', 'automation'], 'due'), (['displacement', 'due', 'automation', 'and'], 'to'), (['due', 'to', 'and', 'the'], 'automation'), (['to', 'automation', 'the', 'risk'], 'and'), (['automation', 'and', 'risk', 'of'], 'the'), (['and', 'the', 'of', 'biases'], 'risk'), (['the', 'risk', 'biases', 'in'], 'of'), (['risk', 'of', 'in', 'ai'], 'biases'), (['of', 'biases', 'ai', 'models'], 'in'), (['biases', 'in', 'models', 'highlight'], 'ai'), (['in', 'ai', 'highlight', 'the'], 'models'), (['ai', 'models', 'the', 'need'], 'highlight'), (['models', 'highlight', 'need', 'for'], 'the'), (['highlight', 'the', 'for', 'responsible'], 'need'), (['the', 'need', 'responsible', 'development'], 'for'), (['need', 'for', 'development', 'and'], 'responsible'), (['for', 'responsible', 'and', 'regulation'], 'development'), (['responsible', 'development', 'regulation', 'as'], 'and'), (['development', 'and', 'as', 'we'], 'regulation'), (['and', 'regulation', 'we', 'continue'], 'as'), (['regulation', 'as', 'continue', 'to'], 'we'), (['as', 'we', 'to', 'innovate'], 'continue'), (['we', 'continue', 'innovate', 'it'], 'to'), (['continue', 'to', 'it', 'is'], 'innovate'), (['to', 'innovate', 'is', 'essential'], 'it'), (['innovate', 'it', 'essential', 'to'], 'is'), (['it', 'is', 'to', 'ensure'], 'essential'), (['is', 'essential', 'ensure', 'that'], 'to'), (['essential', 'to', 'that', 'ai'], 'ensure'), (['to', 'ensure', 'ai', 'serves'], 'that'), (['ensure', 'that', 'serves', 'humanity'], 'ai'), (['that', 'ai', 'humanity', 's'], 'serves'), (['ai', 'serves', 's', 'best'], 'humanity'), (['serves', 'humanity', 'best', 'interests'], 's'), (['humanity', 's', 'interests', 'promoting'], 'best'), (['s', 'best', 'promoting', 'fairness'], 'interests'), (['best', 'interests', 'fairness', 'accountability'], 'promoting'), (['interests', 'promoting', 'accountability', 'and'], 'fairness'), (['promoting', 'fairness', 'and', 'transparency'], 'accountability'), (['fairness', 'accountability', 'transparency', 'embracing'], 'and'), (['accountability', 'and', 'embracing', 'ai'], 'transparency'), (['and', 'transparency', 'ai', 's'], 'embracing'), (['transparency', 'embracing', 's', 'potential'], 'ai'), (['embracing', 'ai', 'potential', 'while'], 's'), (['ai', 's', 'while', 'addressing'], 'potential'), (['s', 'potential', 'addressing', 'these'], 'while'), (['potential', 'while', 'these', 'concerns'], 'addressing'), (['while', 'addressing', 'concerns', 'could'], 'these'), (['addressing', 'these', 'could', 'lead'], 'concerns'), (['these', 'concerns', 'lead', 'to'], 'could'), (['concerns', 'could', 'to', 'a'], 'lead'), (['could', 'lead', 'a', 'future'], 'to'), (['lead', 'to', 'future', 'where'], 'a'), (['to', 'a', 'where', 'technology'], 'future'), (['a', 'future', 'technology', 'empowers'], 'where'), (['future', 'where', 'empowers', 'individuals'], 'technology'), (['where', 'technology', 'individuals', 'and'], 'empowers'), (['technology', 'empowers', 'and', 'communities'], 'individuals'), (['empowers', 'individuals', 'communities', 'driving'], 'and'), (['individuals', 'and', 'driving', 'us'], 'communities'), (['and', 'communities', 'us', 'towards'], 'driving'), (['communities', 'driving', 'towards', 'unprecedented'], 'us'), (['driving', 'us', 'unprecedented', 'levels'], 'towards'), (['us', 'towards', 'levels', 'of'], 'unprecedented'), (['towards', 'unprecedented', 'of', 'efficiency'], 'levels'), (['unprecedented', 'levels', 'efficiency', 'creativity'], 'of'), (['levels', 'of', 'creativity', 'and'], 'efficiency'), (['of', 'efficiency', 'and', 'prosperity'], 'creativity')]\n",
      "[[0.29693277 0.97722656 0.30989492 ... 0.5224676  0.71439247 0.4123052 ]\n",
      " [0.54934258 0.39810209 0.91175868 ... 0.15408357 0.06780851 0.74120904]\n",
      " [0.83199255 0.27734672 0.07605417 ... 0.26011113 0.06732923 0.29392318]\n",
      " ...\n",
      " [0.76249307 0.13866759 0.36366276 ... 0.64309033 0.97681908 0.62961713]\n",
      " [0.17356684 0.05054338 0.11052547 ... 0.34245805 0.16639023 0.32639059]\n",
      " [0.35886463 0.94920332 0.63197611 ... 0.77970336 0.71943418 0.80039952]]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb6f1def-0cdd-408c-8e58-6ca8749d7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 57, 117, 156], [57, 0, 156, 26], [0, 117, 26, 58], [117, 156, 58, 114], [156, 26, 114, 44], [26, 58, 44, 147], [58, 114, 147, 50], [114, 44, 50, 45], [44, 147, 45, 131], [147, 50, 131, 139], [50, 45, 139, 1], [45, 131, 1, 34], [131, 139, 34, 91], [139, 1, 91, 119], [1, 34, 119, 77], [34, 91, 77, 31], [91, 119, 31, 35], [119, 77, 35, 16], [77, 31, 16, 133], [31, 35, 133, 30], [35, 16, 30, 136], [16, 133, 136, 105], [133, 30, 105, 176], [30, 136, 176, 99], [136, 105, 99, 122], [105, 176, 122, 129], [176, 99, 129, 38], [99, 122, 38, 99], [122, 129, 99, 159], [129, 38, 159, 162], [38, 99, 162, 108], [99, 159, 108, 162], [159, 162, 162, 30], [162, 108, 30, 94], [108, 162, 94, 92], [162, 30, 92, 137], [30, 94, 137, 123], [94, 92, 123, 0], [92, 137, 0, 50], [137, 123, 50, 61], [123, 0, 61, 96], [0, 50, 96, 63], [50, 61, 63, 42], [61, 96, 42, 50], [96, 63, 50, 87], [63, 42, 87, 78], [42, 50, 78, 41], [50, 87, 41, 1], [87, 78, 1, 32], [78, 41, 32, 175], [41, 1, 175, 82], [1, 32, 82, 134], [32, 175, 134, 30], [175, 82, 30, 163], [82, 134, 163, 100], [134, 30, 100, 72], [30, 163, 72, 148], [163, 100, 148, 15], [100, 72, 15, 99], [72, 148, 99, 151], [148, 15, 151, 149], [15, 99, 149, 51], [99, 151, 51, 0], [151, 149, 0, 161], [149, 51, 161, 99], [51, 0, 99, 6], [0, 161, 6, 28], [161, 99, 28, 30], [99, 6, 30, 132], [6, 28, 132, 40], [28, 30, 40, 169], [30, 132, 169, 3], [132, 40, 3, 55], [40, 169, 55, 119], [169, 3, 119, 23], [3, 55, 23, 17], [55, 119, 17, 144], [119, 23, 144, 30], [23, 17, 30, 126], [17, 144, 126, 9], [144, 30, 9, 99], [30, 126, 99, 165], [126, 9, 165, 172], [9, 99, 172, 18], [99, 165, 18, 111], [165, 172, 111, 171], [172, 18, 171, 30], [18, 111, 30, 163], [111, 171, 163, 179], [171, 30, 179, 101], [30, 163, 101, 124], [163, 179, 124, 104], [179, 101, 104, 93], [101, 124, 93, 118], [124, 104, 118, 19], [104, 93, 19, 109], [93, 118, 109, 110], [118, 19, 110, 30], [19, 109, 30, 90], [109, 110, 90, 68], [110, 30, 68, 0], [30, 90, 0, 143], [90, 68, 143, 88], [68, 0, 88, 157], [0, 143, 157, 50], [143, 88, 50, 91], [88, 157, 91, 24], [157, 50, 24, 5], [50, 91, 5, 71], [91, 24, 71, 39], [24, 5, 39, 22], [5, 71, 22, 11], [71, 39, 11, 48], [39, 22, 48, 53], [22, 11, 53, 76], [11, 48, 76, 149], [48, 53, 149, 64], [53, 76, 64, 30], [76, 149, 30, 178], [149, 64, 178, 170], [64, 30, 170, 97], [30, 178, 97, 95], [178, 170, 95, 54], [170, 97, 54, 59], [97, 95, 59, 20], [95, 54, 20, 72], [54, 59, 72, 13], [59, 20, 13, 150], [20, 72, 150, 7], [72, 13, 7, 27], [13, 150, 27, 46], [150, 7, 46, 106], [7, 27, 106, 114], [27, 46, 114, 146], [46, 106, 146, 71], [106, 114, 71, 167], [114, 146, 167, 72], [146, 71, 72, 0], [71, 167, 0, 173], [167, 72, 173, 125], [72, 0, 125, 74], [0, 173, 74, 141], [173, 125, 141, 162], [125, 74, 162, 174], [74, 141, 174, 30], [141, 162, 30, 75], [162, 174, 75, 79], [174, 30, 79, 99], [30, 75, 99, 2], [75, 79, 2, 30], [79, 99, 30, 25], [99, 2, 25, 70], [2, 30, 70, 80], [30, 25, 80, 32], [25, 70, 32, 153], [70, 80, 153, 150], [80, 32, 150, 81], [32, 153, 81, 1], [153, 150, 1, 0], [150, 81, 0, 73], [81, 1, 73, 142], [1, 0, 142, 14], [0, 73, 14, 30], [73, 142, 30, 47], [142, 14, 47, 36], [14, 30, 36, 140], [30, 47, 140, 43], [47, 36, 43, 32], [36, 140, 32, 65], [140, 43, 65, 83], [43, 32, 83, 121], [32, 65, 121, 66], [65, 83, 66, 50], [83, 121, 50, 29], [121, 66, 29, 30], [66, 50, 30, 150], [50, 29, 150, 4], [29, 30, 4, 1], [30, 150, 1, 120], [150, 4, 120, 99], [4, 1, 99, 0], [1, 120, 0, 103], [120, 99, 103, 69], [99, 0, 69, 150], [0, 103, 150, 177], [103, 69, 177, 164], [69, 150, 164, 49], [150, 177, 49, 168], [177, 164, 168, 30], [164, 49, 30, 115], [49, 168, 115, 71], [168, 30, 71, 59], [30, 115, 59, 158], [115, 71, 158, 50], [71, 59, 50, 113], [59, 158, 113, 42], [158, 50, 42, 46], [50, 113, 46, 21], [113, 42, 21, 50], [42, 46, 50, 67], [46, 21, 67, 130], [21, 50, 130, 0], [50, 67, 0, 84], [67, 130, 84, 138], [130, 0, 138, 143], [0, 84, 143, 8], [84, 138, 8, 154], [138, 143, 154, 56], [143, 8, 56, 166], [8, 154, 166, 152], [154, 56, 152, 30], [56, 166, 30, 107], [166, 152, 107, 37], [152, 30, 37, 0], [30, 107, 0, 143], [107, 37, 143, 52], [37, 0, 52, 89], [0, 143, 89, 155], [143, 52, 155, 98], [52, 89, 98, 85], [89, 155, 85, 19], [155, 98, 19, 127], [98, 85, 127, 50], [85, 19, 50, 114], [19, 127, 114, 60], [127, 50, 60, 11], [50, 114, 11, 13], [114, 60, 13, 112], [60, 11, 112, 10], [11, 13, 10, 30], [13, 112, 30, 145], [112, 10, 145, 135], [10, 30, 135, 86], [30, 145, 86, 62], [145, 135, 62, 102], [135, 86, 102, 160], [86, 62, 160, 1], [62, 102, 1, 33], [102, 160, 33, 128], [160, 1, 128, 30], [1, 33, 30, 116]]\n",
      "[0, 117, 156, 26, 58, 114, 44, 147, 50, 45, 131, 139, 1, 34, 91, 119, 77, 31, 35, 16, 133, 30, 136, 105, 176, 99, 122, 129, 38, 99, 159, 162, 108, 162, 30, 94, 92, 137, 123, 0, 50, 61, 96, 63, 42, 50, 87, 78, 41, 1, 32, 175, 82, 134, 30, 163, 100, 72, 148, 15, 99, 151, 149, 51, 0, 161, 99, 6, 28, 30, 132, 40, 169, 3, 55, 119, 23, 17, 144, 30, 126, 9, 99, 165, 172, 18, 111, 171, 30, 163, 179, 101, 124, 104, 93, 118, 19, 109, 110, 30, 90, 68, 0, 143, 88, 157, 50, 91, 24, 5, 71, 39, 22, 11, 48, 53, 76, 149, 64, 30, 178, 170, 97, 95, 54, 59, 20, 72, 13, 150, 7, 27, 46, 106, 114, 146, 71, 167, 72, 0, 173, 125, 74, 141, 162, 174, 30, 75, 79, 99, 2, 30, 25, 70, 80, 32, 153, 150, 81, 1, 0, 73, 142, 14, 30, 47, 36, 140, 43, 32, 65, 83, 121, 66, 50, 29, 30, 150, 4, 1, 120, 99, 0, 103, 69, 150, 177, 164, 49, 168, 30, 115, 71, 59, 158, 50, 113, 42, 46, 21, 50, 67, 130, 0, 84, 138, 143, 8, 154, 56, 166, 152, 30, 107, 37, 0, 143, 52, 89, 155, 98, 85, 19, 127, 50, 114, 60, 11, 13, 112, 10, 30, 145, 135, 86, 62, 102, 160, 1, 33, 128]\n"
     ]
    }
   ],
   "source": [
    "context_indices=[[word_to_ix[word] for word in context] for context, _ in data]\n",
    "target_indices=[word_to_ix[target]for _,target in data]\n",
    "\n",
    "print(context_indices)\n",
    "print(target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c41669d-5df2-4d67-9069-dc4e6d0a2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4af44de0-819b-4ddc-9de5-43a10ea04b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into array\n",
    "x_train=np.array(context_indices)\n",
    "y_train=np.array(target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56493531-4005-46e8-bd6d-9fa3434825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=embed_dim,input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9504c4d3-5b59-4a63-94ff-c76a38b88fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93e7e237-27e5-480c-8799-5946cb76f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 5.1941\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0237 - loss: 5.1843   \n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0221 - loss: 5.1767   \n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0761 - loss: 5.1682\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1081 - loss: 5.1611\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1992 - loss: 5.1517\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2233 - loss: 5.1425\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2965 - loss: 5.1335\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3068 - loss: 5.1222\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3544 - loss: 5.1105\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4010 - loss: 5.0969\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3891 - loss: 5.0858\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4378 - loss: 5.0685\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4993 - loss: 5.0557\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5211 - loss: 5.0356\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6079 - loss: 5.0150\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5738 - loss: 4.9932\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6630 - loss: 4.9732\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6984 - loss: 4.9484\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7096 - loss: 4.9193\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7676 - loss: 4.8876\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8150 - loss: 4.8532\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7882 - loss: 4.8289\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 4.7871  \n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 4.7448\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9229 - loss: 4.7036\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9164 - loss: 4.6529\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9201 - loss: 4.6069\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 4.5392\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9256 - loss: 4.5115\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9280 - loss: 4.4455\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9427 - loss: 4.3801 \n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9378 - loss: 4.3302\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 4.2403\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 4.1896\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 4.1184\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 4.0234\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9630 - loss: 3.9767\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9660 - loss: 3.8835\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9503 - loss: 3.8199\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 3.7163\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9598 - loss: 3.6329\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 3.5391\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9681 - loss: 3.4348\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 3.3838\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9465 - loss: 3.3066\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 3.1915 \n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 3.0654\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 3.0173\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9694 - loss: 2.8901\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9521 - loss: 2.8323\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 2.7378\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 2.6504  \n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 2.4790\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9810 - loss: 2.4683\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 2.3367\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 2.2471\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 2.1716\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 2.0513\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 2.0161\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 1.8818  \n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 1.8209\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 1.7531\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 1.6700\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 1.6337\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 1.5390\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 1.4790\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 1.3667\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 1.3151\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 1.2567\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 1.1866\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 1.1587\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 1.0598\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 1.0202\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.9704\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.9141\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.8777\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.8524\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.8070\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.7819\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.7175\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.7040\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.6899\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.6422\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.6227 \n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.5846\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.5574\n",
      "Epoch 88/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.5305\n",
      "Epoch 89/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.5132\n",
      "Epoch 90/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.5013\n",
      "Epoch 91/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9915 - loss: 0.4785\n",
      "Epoch 92/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.4354\n",
      "Epoch 93/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.4197\n",
      "Epoch 94/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.4194\n",
      "Epoch 95/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.3932\n",
      "Epoch 96/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.3781\n",
      "Epoch 97/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.3784\n",
      "Epoch 98/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.3544\n",
      "Epoch 99/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.3407\n",
      "Epoch 100/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.3342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b05a2f7810>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,verbose=1)\n",
    "#verbose is used when we want to monitor traning process and how performance will change over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b366f07d-c44d-42c7-8c03-16c9338d63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Predicted word is: to\n"
     ]
    }
   ],
   "source": [
    "example_context=['potentially','need','risk','rise']\n",
    "example_context_indices=np.array([word_to_ix[word] for word in example_context])\n",
    "example_context_indices = example_context_indices.reshape(1, -1)\n",
    "\n",
    "predicted=model.predict(example_context_indices)\n",
    "predicted_word_index=np.argmax(predicted,axis=-1) #finds the index of the highest value in the predicted array\n",
    "predicted_word=list(word_to_ix.keys())[predicted_word_index[0]] #Using predicted_word_index[0], we retrieve the actual word associated with the index\n",
    "print(\"Predicted word is:\", predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558395e-a45c-47f2-b4bc-81b8b3c1c381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
